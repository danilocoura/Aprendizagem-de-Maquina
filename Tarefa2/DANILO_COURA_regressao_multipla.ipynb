{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Múltipla do Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar Bibliotecas Numpy e LinearRegression, para comparação com a versão implementada do zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular a norma dos vetores (L2):\n",
    "\n",
    "$||\\mathbf{w}||_2 = \\sqrt{w^T*w}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_norma(gradient):\n",
    "    return np.sqrt(np.dot(gradient.T,gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Função para calcular o MSE (Mean Squared Error):\n",
    "\n",
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse_vectorized(w,X,Y):\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para fazer uma atualização dos parâmetros no Gradiente Descendente:\n",
    "\n",
    "$w_M = w_M + 2\\alpha\\sum_{i=1}^N x_i(y_i - (w_0+w_1x_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    m = np.size(w_current,0)\n",
    "    res = Y - np.dot(X,w_current)\n",
    "    gradient = np.zeros((m,1))\n",
    "    w = np.zeros((m,1))\n",
    "    gradient = np.sum(np.multiply(res,X),axis=0)[:,np.newaxis]\n",
    "    w = w_current + (2 * learningRate * gradient)\n",
    "    return [w,gradient]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para iterar sobre o gradiente descendente até convergência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(w, X,Y, learning_rate, epsilon):\n",
    "\ti = 0\n",
    "\tnorma = float('inf')\n",
    "\twhile (norma>=epsilon):\n",
    "\t\t[w,gradient] = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "\t\tnorma = compute_norma(gradient)\n",
    "\t\tif i % 10000 == 0:\n",
    "\t\t\tprint(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "\t\t\tprint(\"epsilon na iteração {0} é de {1}\".format(i,norma))\n",
    "\t\ti+= 1\n",
    "\tprint(\"MSE na iteração final {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))    \n",
    "\tprint(\"epsilon na iteração final {0} é de {1}\".format(i,norma))\n",
    "\treturn w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura e separação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = np.genfromtxt(\"sample_treino.csv\", delimiter=\",\", skip_header=1);\n",
    "points = np.c_[np.ones(len(points)),points];\n",
    "X = points[:,0:5];\n",
    "Y = points[:,6][:,np.newaxis];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialização dos coeficientes, taxa de aprendizagem e limiar de parada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_w = np.zeros((5,1));\n",
    "learning_rate = 0.00004;\n",
    "epsilon = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada do algoritmo de Regressão Múltipla do Zero e retorno dos coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE na iteração 0 é de [[ 30.83908673]]\n",
      "epsilon na iteração 0 é de [[ 10195.06808199]]\n",
      "MSE na iteração 10000 é de [[ 0.42003011]]\n",
      "epsilon na iteração 10000 é de [[ 0.67116604]]\n",
      "MSE na iteração 20000 é de [[ 0.4148794]]\n",
      "epsilon na iteração 20000 é de [[ 0.40462411]]\n",
      "MSE na iteração 30000 é de [[ 0.41300738]]\n",
      "epsilon na iteração 30000 é de [[ 0.24393467]]\n",
      "MSE na iteração 40000 é de [[ 0.41232699]]\n",
      "epsilon na iteração 40000 é de [[ 0.14706025]]\n",
      "MSE na iteração 50000 é de [[ 0.41207971]]\n",
      "epsilon na iteração 50000 é de [[ 0.08865783]]\n",
      "MSE na iteração 60000 é de [[ 0.41198983]]\n",
      "epsilon na iteração 60000 é de [[ 0.05344891]]\n",
      "MSE na iteração 70000 é de [[ 0.41195717]]\n",
      "epsilon na iteração 70000 é de [[ 0.03222261]]\n",
      "MSE na iteração 80000 é de [[ 0.41194529]]\n",
      "epsilon na iteração 80000 é de [[ 0.01942596]]\n",
      "MSE na iteração 90000 é de [[ 0.41194098]]\n",
      "epsilon na iteração 90000 é de [[ 0.01171128]]\n",
      "MSE na iteração 100000 é de [[ 0.41193941]]\n",
      "epsilon na iteração 100000 é de [[ 0.00706035]]\n",
      "MSE na iteração 110000 é de [[ 0.41193884]]\n",
      "epsilon na iteração 110000 é de [[ 0.00425645]]\n",
      "MSE na iteração 120000 é de [[ 0.41193863]]\n",
      "epsilon na iteração 120000 é de [[ 0.00256608]]\n",
      "MSE na iteração 130000 é de [[ 0.41193856]]\n",
      "epsilon na iteração 130000 é de [[ 0.001547]]\n",
      "MSE na iteração 140000 é de [[ 0.41193853]]\n",
      "epsilon na iteração 140000 é de [[ 0.00093264]]\n",
      "MSE na iteração 150000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 150000 é de [[ 0.00056226]]\n",
      "MSE na iteração 160000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 160000 é de [[ 0.00033897]]\n",
      "MSE na iteração 170000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 170000 é de [[ 0.00020435]]\n",
      "MSE na iteração 180000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 180000 é de [[ 0.0001232]]\n",
      "MSE na iteração final 184124 é de [[ 0.41193851]]\n",
      "epsilon na iteração final 184124 é de [[  9.99966996e-05]]\n",
      "Os coeficientes obtidos na Regressão Múltipla do Zero são: \n",
      " [[ 1.78985948]\n",
      " [ 0.10676925]\n",
      " [ 0.04638778]\n",
      " [ 0.16818843]\n",
      " [ 0.3835476 ]]\n"
     ]
    }
   ],
   "source": [
    "w_do_zero = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "print(\"Os coeficientes obtidos na Regressão Múltipla do Zero são: \\n {0}\".format(w_do_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada do algoritmo de Regressão Múltipla do SKLEARN e retorno dos coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os coeficientes obtidos na Regressão Múltipla do sklearn são: \n",
      " [[ 1.79001712]\n",
      " [ 0.10676596]\n",
      " [ 0.04638034]\n",
      " [ 0.16818839]\n",
      " [ 0.3835391 ]]\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X,Y)\n",
    "w_sklearn = clf.coef_.T\n",
    "w_sklearn[0,0] = clf.intercept_\n",
    "print(\"Os coeficientes obtidos na Regressão Múltipla do sklearn são: \\n {0}\".format(w_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular o MSE (Mean Squared Error) entre os coeficientes de ambos os métodos:\n",
    "\n",
    "$MSE=\\frac{1}{N}(wdozero - wsklearn)^T*(wdozero - wsklearn)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A diferença entre o os vetores que representam os coeficientes de ambas as abordagens é: \n",
      " [[  4.99756719e-09]]\n"
     ]
    }
   ],
   "source": [
    "def compute_mse_coefs(w_dozero, w_sklearn):\n",
    "    res = w_dozero - w_sklearn\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(w_dozero))\n",
    "print(\"A diferença entre o os vetores que representam os coeficientes de ambas as abordagens é: \\n {0}\".format(compute_mse_coefs(w_do_zero,w_sklearn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
