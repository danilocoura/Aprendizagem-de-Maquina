{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Múltipla do Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar Bibliotecas Numpy e LinearRegression, para comparação com a versão implementada do zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular a norma dos vetores (L2):\n",
    "\n",
    "$||\\mathbf{w}||_2 = \\sqrt{w^T*w}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_norma(gradient):\n",
    "    return np.sqrt(np.dot(gradient.T,gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Função para calcular o MSE (Mean Squared Error):\n",
    "\n",
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse_vectorized(w,X,Y):\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para fazer uma atualização dos parâmetros no Gradiente Descendente:\n",
    "\n",
    "$w_M = w_M + 2\\alpha\\sum_{i=1}^N x_i(y_i - (w_0+w_1x_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    m = np.size(w_current,0)\n",
    "    res = Y - np.dot(X,w_current)\n",
    "    gradient = np.zeros((m,1))\n",
    "    w = np.zeros((m,1))\n",
    "    gradient = np.sum(np.multiply(res,X),axis=0)[:,np.newaxis]\n",
    "    w = w_current + (2 * learningRate * gradient)\n",
    "    return [w,gradient]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para iterar sobre o gradiente descendente até convergência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(w, X,Y, learning_rate, epsilon):\n",
    "    i = 0\n",
    "    norma = float('inf')\n",
    "    while (norma>=epsilon):\n",
    "        [w,gradient] = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        if i % 10000 == 0:\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "            norma = compute_norma(gradient)\n",
    "            print(\"epsilon na iteração {0} é de {1}\".format(i,norma))\n",
    "        i+= 1\n",
    "    print(\"MSE na iteração final {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))    \n",
    "    print(\"epsilon na iteração final {0} é de {1}\".format(i,norma))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura e separação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = np.genfromtxt(\"sample_treino.csv\", delimiter=\",\", skip_header=1);\n",
    "points = np.c_[np.ones(len(points)),points];\n",
    "X = points[:,0:5];\n",
    "Y = points[:,6][:,np.newaxis];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialização dos coeficientes, taxa de aprendizagem e limiar de parada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_w = np.zeros((5,1));\n",
    "learning_rate = 0.00003;\n",
    "epsilon = 0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada do algoritmo de Regressão Múltipla do Zero e retorno dos coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE na iteração 0 é de [[ 615.40235155]]\n",
      "epsilon na iteração 0 é de [[ 10195.06808199]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danilo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in add\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE na iteração 10000 é de [[ nan]]\n",
      "epsilon na iteração 10000 é de [[ nan]]\n",
      "MSE na iteração final 10001 é de [[ nan]]\n",
      "epsilon na iteração final 10001 é de [[ nan]]\n",
      "Os coeficientes obtidos na Regressão Múltipla do Zero são: \n",
      " [[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danilo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "w_do_zero = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "print(\"Os coeficientes obtidos na Regressão Múltipla do Zero são: \\n {0}\".format(w_do_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada do algoritmo de Regressão Múltipla do SKLEARN e retorno dos coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os coeficientes obtidos na Regressão Múltipla do sklearn são: \n",
      " [[ 1.79001712]\n",
      " [ 0.10676596]\n",
      " [ 0.04638034]\n",
      " [ 0.16818839]\n",
      " [ 0.3835391 ]]\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X,Y)\n",
    "w_sklearn = clf.coef_.T\n",
    "w_sklearn[0,0] = clf.intercept_\n",
    "print(\"Os coeficientes obtidos na Regressão Múltipla do sklearn são: \\n {0}\".format(w_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular o MSE (Mean Squared Error) entre os coeficientes de ambos os métodos:\n",
    "\n",
    "$MSE=\\frac{1}{N}(wdozero - wsklearn)^T*(wdozero - wsklearn)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A diferença entre o os vetores que representam os coeficientes de ambas as abordagens é: \n",
      " [[  3.73587284e-11]]\n"
     ]
    }
   ],
   "source": [
    "def compute_mse_coefs(w_dozero, w_sklearn):\n",
    "    res = w_dozero - w_sklearn\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(w_dozero))\n",
    "print(\"A diferença entre o os vetores que representam os coeficientes de ambas as abordagens é: \\n {0}\".format(compute_mse_coefs(w_do_zero,w_sklearn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
