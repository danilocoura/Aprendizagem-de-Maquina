{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Múltipla do Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar Bibliotecas Numpy e LinearRegression, para comparação com a versão implementada do zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular a norma dos vetores (L2):\n",
    "\n",
    "$||\\mathbf{w}||_2 = \\sqrt{w^T*w}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_norma(gradient):\n",
    "    return np.sqrt(np.dot(gradient.T,gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Função para calcular o MSE (Mean Squared Error):\n",
    "\n",
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse_vectorized(w,X,Y):\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para fazer uma atualização dos parâmetros no Gradiente Descendente:\n",
    "\n",
    "$w_M = w_M + 2\\alpha\\sum_{i=1}^N x_i(y_i - (w_0+w_1x_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    m = np.size(w_current,0)\n",
    "    res = Y - np.dot(X,w_current)\n",
    "    gradient = np.zeros((m,1))\n",
    "    w = np.zeros((m,1))\n",
    "    gradient = np.sum(np.multiply(res,X),axis=0)[:,np.newaxis]\n",
    "    w = w_current + (2 * learningRate * gradient)\n",
    "    return [w,gradient]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para iterar sobre o gradiente descendente até convergência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(w, X,Y, learning_rate, epsilon):\n",
    "    i = 0\n",
    "    norma = float('inf')\n",
    "    while (norma>=epsilon):\n",
    "        [w,gradient] = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        if i % 10000 == 0:\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "            norma = compute_norma(gradient)\n",
    "            print(\"epsilon na iteração {0} é de {1}\".format(i,norma))\n",
    "        i+= 1\n",
    "    print(\"MSE na iteração final {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))    \n",
    "    print(\"epsilon na iteração final {0} é de {1}\".format(i,norma))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura e separação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = np.genfromtxt(\"sample_treino.csv\", delimiter=\",\", skip_header=1);\n",
    "points = np.c_[np.ones(len(points)),points];\n",
    "X = points[:,0:5];\n",
    "Y = points[:,6][:,np.newaxis];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialização dos coeficientes, taxa de aprendizagem e limiar de parada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_w = np.zeros((5,1));\n",
    "learning_rate = 0.00003;\n",
    "epsilon = 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada do algoritmo de Regressão Múltipla do Zero e retorno dos coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE na iteração 0 é de [[ 5.74807523]]\n",
      "epsilon na iteração 0 é de [[ 10195.06808199]]\n",
      "MSE na iteração 10000 é de [[ 0.42236016]]\n",
      "epsilon na iteração 10000 é de [[ 0.76168529]]\n",
      "MSE na iteração 20000 é de [[ 0.41681684]]\n",
      "epsilon na iteração 20000 é de [[ 0.52112625]]\n",
      "MSE na iteração 30000 é de [[ 0.41422204]]\n",
      "epsilon na iteração 30000 é de [[ 0.3565417]]\n",
      "MSE na iteração 40000 é de [[ 0.41300742]]\n",
      "epsilon na iteração 40000 é de [[ 0.24393701]]\n",
      "MSE na iteração 50000 é de [[ 0.41243887]]\n",
      "epsilon na iteração 50000 é de [[ 0.16689567]]\n",
      "MSE na iteração 60000 é de [[ 0.41217273]]\n",
      "epsilon na iteração 60000 é de [[ 0.11418589]]\n",
      "MSE na iteração 70000 é de [[ 0.41204815]]\n",
      "epsilon na iteração 70000 é de [[ 0.07812317]]\n",
      "MSE na iteração 80000 é de [[ 0.41198983]]\n",
      "epsilon na iteração 80000 é de [[ 0.05344994]]\n",
      "MSE na iteração 90000 é de [[ 0.41196254]]\n",
      "epsilon na iteração 90000 é de [[ 0.03656913]]\n",
      "MSE na iteração 100000 é de [[ 0.41194976]]\n",
      "epsilon na iteração 100000 é de [[ 0.02501969]]\n",
      "MSE na iteração 110000 é de [[ 0.41194378]]\n",
      "epsilon na iteração 110000 é de [[ 0.01711786]]\n",
      "MSE na iteração 120000 é de [[ 0.41194098]]\n",
      "epsilon na iteração 120000 é de [[ 0.01171161]]\n",
      "MSE na iteração 130000 é de [[ 0.41193967]]\n",
      "epsilon na iteração 130000 é de [[ 0.0080128]]\n",
      "MSE na iteração 140000 é de [[ 0.41193905]]\n",
      "epsilon na iteração 140000 é de [[ 0.00548216]]\n",
      "MSE na iteração 150000 é de [[ 0.41193877]]\n",
      "epsilon na iteração 150000 é de [[ 0.00375076]]\n",
      "MSE na iteração 160000 é de [[ 0.41193863]]\n",
      "epsilon na iteração 160000 é de [[ 0.00256617]]\n",
      "MSE na iteração 170000 é de [[ 0.41193857]]\n",
      "epsilon na iteração 170000 é de [[ 0.00175571]]\n",
      "MSE na iteração 180000 é de [[ 0.41193854]]\n",
      "epsilon na iteração 180000 é de [[ 0.00120122]]\n",
      "MSE na iteração 190000 é de [[ 0.41193853]]\n",
      "epsilon na iteração 190000 é de [[ 0.00082184]]\n",
      "MSE na iteração 200000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 200000 é de [[ 0.00056228]]\n",
      "MSE na iteração 210000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 210000 é de [[ 0.0003847]]\n",
      "MSE na iteração 220000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 220000 é de [[ 0.0002632]]\n",
      "MSE na iteração 230000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 230000 é de [[ 0.00018008]]\n",
      "MSE na iteração 240000 é de [[ 0.41193852]]\n",
      "epsilon na iteração 240000 é de [[ 0.0001232]]\n",
      "MSE na iteração 250000 é de [[ 0.41193851]]\n",
      "epsilon na iteração 250000 é de [[  8.42932170e-05]]\n",
      "MSE na iteração 260000 é de [[ 0.41193851]]\n",
      "epsilon na iteração 260000 é de [[  5.76713352e-05]]\n",
      "MSE na iteração 270000 é de [[ 0.41193851]]\n",
      "epsilon na iteração 270000 é de [[  3.94573018e-05]]\n",
      "MSE na iteração 280000 é de [[ 0.41193851]]\n",
      "epsilon na iteração 280000 é de [[  2.69957104e-05]]\n",
      "MSE na iteração 290000 é de [[ 0.41193851]]\n",
      "epsilon na iteração 290000 é de [[  1.84697977e-05]]\n",
      "MSE na iteração 300000 é de [[ 0.41193851]]\n",
      "epsilon na iteração 300000 é de [[  1.26365790e-05]]\n",
      "MSE na iteração 310000 é de [[ 0.41193851]]\n",
      "epsilon na iteração 310000 é de [[  8.64563493e-06]]\n",
      "MSE na iteração final 310001 é de [[ 0.41193851]]\n",
      "epsilon na iteração final 310001 é de [[  8.64563493e-06]]\n",
      "Os coeficientes obtidos na Regressão Múltipla do Zero são: \n",
      " [[ 1.79000349]\n",
      " [ 0.10676625]\n",
      " [ 0.04638098]\n",
      " [ 0.1681884 ]\n",
      " [ 0.38353983]]\n"
     ]
    }
   ],
   "source": [
    "w_do_zero = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "print(\"Os coeficientes obtidos na Regressão Múltipla do Zero são: \\n {0}\".format(w_do_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada do algoritmo de Regressão Múltipla do SKLEARN e retorno dos coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os coeficientes obtidos na Regressão Múltipla do sklearn são: \n",
      " [[ 1.79001712]\n",
      " [ 0.10676596]\n",
      " [ 0.04638034]\n",
      " [ 0.16818839]\n",
      " [ 0.3835391 ]]\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X,Y)\n",
    "w_sklearn = clf.coef_.T\n",
    "w_sklearn[0,0] = clf.intercept_\n",
    "print(\"Os coeficientes obtidos na Regressão Múltipla do sklearn são: \\n {0}\".format(w_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular o MSE (Mean Squared Error) entre os coeficientes de ambos os métodos:\n",
    "\n",
    "$MSE=\\frac{1}{N}(wdozero - wsklearn)^T*(wdozero - wsklearn)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A diferença entre o os vetores que representam os coeficientes de ambas as abordagens é: \n",
      " [[  3.73587284e-11]]\n"
     ]
    }
   ],
   "source": [
    "def compute_mse_coefs(w_dozero, w_sklearn):\n",
    "    res = w_dozero - w_sklearn\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(w_dozero))\n",
    "print(\"A diferença entre o os vetores que representam os coeficientes de ambas as abordagens é: \\n {0}\".format(compute_mse_coefs(w_do_zero,w_sklearn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
