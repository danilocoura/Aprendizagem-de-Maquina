{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística do Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar Bibliotecas Numpy e LogisticRegression, para comparação com a versão implementada do zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define w_do_zero como variável global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global w_do_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que lê e organiza dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def organize_data(file):\n",
    "\tdata = pd.read_csv(file)\n",
    "\tdata = np.c_[np.ones(len(data)),data];\n",
    "\tX = data[:,0:5].astype('long');\n",
    "\tY = data[:,5][:,np.newaxis];\n",
    "\tY[Y == 'Iris-setosa'] = 0\n",
    "\tY[(Y == 'Iris-versicolor') | (Y == 'Iris-virginica')] = 1\n",
    "\tY = Y.astype('long')\n",
    "\treturn [X, Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular a norma dos vetores (L2):\n",
    "\n",
    "$$||\\mathbf{w}||_2 = \\sqrt{w^T*w}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_norma(gradient):\n",
    "    return np.sqrt(np.dot(gradient.T,gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funçao Sigmóide\n",
    "\n",
    "$$\n",
    "\\sigma(Z)=\\frac{1}{1+e^{-Z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Função para calcular o Custo\n",
    "\n",
    "$$J({\\theta})=\\frac{1}{m}\\sum_{i=1}^m [-y^{(i)}log(h_\\theta(x^{(i)})) - (1-y^{(i)})log(1-h_\\theta(x^{(i)}))]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost_func(w,X,Y):\n",
    "    m = np.size(w,0)\n",
    "    hx = sigmoid(np.dot(X,w))\n",
    "    return (np.dot(Y.T,np.log(hx)) + np.dot((1 - Y).T,np.log(1-hx)))*(-1/m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para fazer uma atualização dos parâmetros no Gradiente Descendente:\n",
    "\n",
    "$$\\frac{\\partial J({\\theta})}{\\partial \\theta_j}=(\\frac 1 m \\sum_{i=1}^m (h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)})$$\n",
    "\n",
    "$$w_M = w_M - \\alpha * \\frac{\\partial J({\\theta})}{\\partial \\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    m = np.size(w_current,0)\n",
    "    hx = sigmoid(np.dot(X,w_current))\n",
    "    gradient = np.zeros((m,1))\n",
    "    w = np.zeros((m,1))\n",
    "    gradient = (np.dot(X.T,hx-Y) * (1/m))\n",
    "    w = w_current - (learningRate * gradient)\n",
    "    return [w,gradient]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para iterar sobre o gradiente descendente até convergência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(w, X,Y, learning_rate, epsilon):\n",
    "\ti = 0\n",
    "\tnorma = float('inf')\n",
    "\twhile (norma>=epsilon):\n",
    "\t\ti+= 1\n",
    "\t\t[w,gradient] = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "\t\tnorma = compute_norma(gradient)\n",
    "\t\t#if i % 10000 == 0:\n",
    "\t\tif i % 50 == 0:\n",
    "\t\t\tprint(\"Custo na iteração {0} é de {1}\".format(i,compute_cost_func(w, X, Y)))\n",
    "\t\t\tprint(\"epsilon na iteração {0} é de {1}\".format(i,norma))\n",
    "\tprint(\"Custo na iteração final {0} é de {1}\".format(i,compute_cost_func(w, X, Y)))    \n",
    "\tprint(\"epsilon na iteração final {0} é de {1}\".format(i,norma))\n",
    "\treturn w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que realiza a predição de acordo com os vetores de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "\thx = sigmoid(np.dot(X,w_do_zero))\n",
    "\thx[hx>= 0.5] = 1\n",
    "\thx[hx< 0.5] = 0\n",
    "\treturn hx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que retorna a acurácia (entre 0 e 1) de acordo com os vetores de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(X,Y):\n",
    "\thx = predict(X)\n",
    "\tZ = np.zeros((hx.shape[0],hx.shape[1]))\n",
    "\tZ[hx==Y] = 1\t\n",
    "\treturn np.sum(Z)/hx.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura e organização dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[X, Y] = organize_data(\"iris\\iris.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialização dos coeficientes, taxa de aprendizagem e limiar de parada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[X, Y] = organize_data(\"iris\\iris.data\")\n",
    "init_w = np.zeros((X.shape[1],1));\n",
    "learning_rate = 0.25;\n",
    "epsilon = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada do algoritmo de Regressão Múltipla do Zero e retorno dos coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo na iteração 50 é de [[ 0.00059305]]\n",
      "epsilon na iteração 50 é de [[ 0.0034782]]\n",
      "Custo na iteração 100 é de [[ 0.00048068]]\n",
      "epsilon na iteração 100 é de [[ 0.00260152]]\n",
      "Custo na iteração 150 é de [[ 0.00041414]]\n",
      "epsilon na iteração 150 é de [[ 0.00205644]]\n",
      "Custo na iteração 200 é de [[ 0.00037105]]\n",
      "epsilon na iteração 200 é de [[ 0.00168343]]\n",
      "Custo na iteração 250 é de [[ 0.00034145]]\n",
      "epsilon na iteração 250 é de [[ 0.00141168]]\n",
      "Custo na iteração 300 é de [[ 0.00032025]]\n",
      "epsilon na iteração 300 é de [[ 0.00120487]]\n",
      "Custo na iteração 350 é de [[ 0.0003046]]\n",
      "epsilon na iteração 350 é de [[ 0.00104244]]\n",
      "Custo na iteração 400 é de [[ 0.00029275]]\n",
      "epsilon na iteração 400 é de [[ 0.00091185]]\n",
      "Custo na iteração 450 é de [[ 0.0002836]]\n",
      "epsilon na iteração 450 é de [[ 0.00080498]]\n",
      "Custo na iteração 500 é de [[ 0.00027641]]\n",
      "epsilon na iteração 500 é de [[ 0.00071635]]\n",
      "Custo na iteração 550 é de [[ 0.00027067]]\n",
      "epsilon na iteração 550 é de [[ 0.00064211]]\n",
      "Custo na iteração 600 é de [[ 0.00026603]]\n",
      "epsilon na iteração 600 é de [[ 0.00057945]]\n",
      "Custo na iteração 650 é de [[ 0.00026223]]\n",
      "epsilon na iteração 650 é de [[ 0.00052628]]\n",
      "Custo na iteração final 679 é de [[ 0.00026033]]\n",
      "epsilon na iteração final 679 é de [[ 0.00049914]]\n",
      "Os coeficientes obtidos na Regressão Múltipla do Zero são: \n",
      " [[-1.01692759]\n",
      " [-1.50673209]\n",
      " [-4.64755865]\n",
      " [ 8.06632585]\n",
      " [ 3.39743067]]\n"
     ]
    }
   ],
   "source": [
    "w_do_zero = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "print(\"Os coeficientes obtidos na Regressão Múltipla do Zero são: \\n {0}\".format(w_do_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada do algoritmo de Regressão Logística do SKLEARN e retorno dos coeficientes (Sem regularização --> C=1e15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os coeficientes obtidos na Regressão Múltipla do sklearn são: \n",
      " [[-1.11021902]\n",
      " [-1.26810489]\n",
      " [-4.11815761]\n",
      " [ 7.48821009]\n",
      " [ 3.59709209]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1e15)\n",
    "clf.fit(X,Y.reshape(Y.shape[0]))\n",
    "w_sklearn = clf.coef_.T\n",
    "w_sklearn[0,0] = clf.intercept_\n",
    "print(\"Os coeficientes obtidos na Regressão Múltipla do sklearn são: \\n {0}\".format(w_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular o MSE (Mean Squared Error) entre os coeficientes de ambos os métodos:\n",
    "\n",
    "$MSE=\\frac{1}{N}(wdozero - wsklearn)^T*(wdozero - wsklearn)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A diferença entre o os vetores que representam os coeficientes de ambas as abordagens é: \n",
      " [[ 0.14399884]]\n"
     ]
    }
   ],
   "source": [
    "def compute_mse_coefs(w_dozero, w_sklearn):\n",
    "    res = w_dozero - w_sklearn\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(w_dozero))\n",
    "print(\"A diferença entre o os vetores que representam os coeficientes de ambas as abordagens é: \\n {0}\".format(compute_mse_coefs(w_do_zero,w_sklearn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A diferença entre os vetores de coeficientes é desprezível. Dessa forma, o código do zero é equivalente ao da biblioteca SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "predict() e score() do método implementado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO IMPLEMENTADO] As predições para o(s) vetor(es) de entrada são: \n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.]\n",
      "[MODELO IMPLEMENTADO] A acurácia da predição do(s) vetor(es) de entrada é: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"[MODELO IMPLEMENTADO] As predições para o(s) vetor(es) de entrada são: \\n {0}\".format(predict(X).reshape(X.shape[0],)))\n",
    "print(\"[MODELO IMPLEMENTADO] A acurácia da predição do(s) vetor(es) de entrada é: {0}\".format(score(X,Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] As predições para o(s) vetor(es) de entrada são: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "[SKLEARN] A acurácia da predição do(s) vetor(es) de entrada é: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"[SKLEARN] As predições para o(s) vetor(es) de entrada são: \\n {0}\".format(clf.predict(X)))\n",
    "print(\"[SKLEARN] A acurácia da predição do(s) vetor(es) de entrada é: {0}\".format(clf.score(X,Y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
